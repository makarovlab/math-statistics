{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"words2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(input_string):\n",
    "    def replace_punctuation_with_space(input_string):\n",
    "        return re.sub(r'[\\.\\!\\-\\_]', ' ', input_string)\n",
    "\n",
    "    def split_string(input_string, chunk_size):\n",
    "        return [input_string[i:i+chunk_size] for i in range(0, len(input_string), chunk_size)]\n",
    "\n",
    "    no_symbols = replace_punctuation_with_space(input_string).lower()\n",
    "    no_symbols = no_symbols.replace(\" \", \"\")\n",
    "    # tokenized = re.split(\"\\W+\", no_symbols.lower())\n",
    "    tokenized = split_string(no_symbols, 3)\n",
    "    return tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/max/.local/lib/python3.10/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>]</th>\n",
       "      <th>aco</th>\n",
       "      <th>act</th>\n",
       "      <th>acy</th>\n",
       "      <th>add</th>\n",
       "      <th>ade</th>\n",
       "      <th>ado</th>\n",
       "      <th>adv</th>\n",
       "      <th>...</th>\n",
       "      <th>y</th>\n",
       "      <th>yco</th>\n",
       "      <th>yho</th>\n",
       "      <th>yid</th>\n",
       "      <th>yis</th>\n",
       "      <th>yna</th>\n",
       "      <th>ys</th>\n",
       "      <th>z</th>\n",
       "      <th>zip</th>\n",
       "      <th>zon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 394 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     1    2    ]  aco  act  acy  add  ade  ado  adv  ...    y  yco  yho  yid  \\\n",
       "0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
       "1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
       "2  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
       "3  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
       "4  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
       "\n",
       "   yis  yna   ys    z  zip  zon  \n",
       "0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "1  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "2  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "3  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "4  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "\n",
       "[5 rows x 394 columns]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# count_vect = CountVectorizer(ngram_range=(1,1), analyzer=clean_text)\n",
    "count_vect = TfidfVectorizer(analyzer=clean_text)\n",
    "\n",
    "vectorizer = count_vect.fit(df['text'])\n",
    "X = vectorizer.transform(df['text'])\n",
    "\n",
    "tokenized_df = pd.DataFrame(X.toarray(), columns=count_vect.get_feature_names())\n",
    "tokenized_df.head()\n",
    "# tokenized_df.to_csv(\"tokenized.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['address' 'city' 'country' 'email' 'housenumber' 'lat' 'location' 'lon'\n",
      " 'opening_hours' 'phone' 'placename' 'postcode' 'ref' 'state' 'store_url'\n",
      " 'street' 'unknown']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(285, 17)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_labels = df['label'].drop_duplicates().to_list()\n",
    "\n",
    "l_encoder = LabelEncoder()\n",
    "l_encoder.fit(y_labels)\n",
    "\n",
    "y = l_encoder.transform(df['label'])\n",
    "print(l_encoder.classes_)\n",
    "\n",
    "y = to_categorical(y)\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import gradient_descent_v2\n",
    "from keras.losses import categorical_crossentropy\n",
    "from keras.metrics import Accuracy, Precision, accuracy\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(213, 394)\n",
      "(72, 394)\n",
      "(213, 17)\n",
      "(72, 17)\n"
     ]
    }
   ],
   "source": [
    "val, input_n = X_train.shape\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_17 (Dense)            (None, 50)                19750     \n",
      "                                                                 \n",
      " dense_18 (Dense)            (None, 17)                867       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 20,617\n",
      "Trainable params: 20,617\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "hidden_n = 50\n",
    "model = Sequential()\n",
    "model.add(Dense(hidden_n, activation=\"relu\", input_shape=(input_n,)))\n",
    "model.add(Dense(17, activation=\"sigmoid\", input_shape=(hidden_n,)))\n",
    "\n",
    "optimizer = gradient_descent_v2.SGD(learning_rate=0.3)\n",
    "model.compile(\n",
    "    optimizer=optimizer,\n",
    "    metrics=[\n",
    "        Accuracy(),\n",
    "        Precision(),\n",
    "    ],\n",
    "    loss=categorical_crossentropy\n",
    ")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 969us/step - loss: 2.7927 - accuracy: 0.0000e+00 - precision_9: 0.0778\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 0s 906us/step - loss: 2.6726 - accuracy: 0.0000e+00 - precision_9: 0.1116\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 0s 911us/step - loss: 2.5737 - accuracy: 0.0000e+00 - precision_9: 0.1127\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 0s 882us/step - loss: 2.5048 - accuracy: 0.0000e+00 - precision_9: 0.1120\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 0s 802us/step - loss: 2.4523 - accuracy: 0.0000e+00 - precision_9: 0.1205\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 0s 860us/step - loss: 2.4110 - accuracy: 0.0000e+00 - precision_9: 0.1228\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 0s 801us/step - loss: 2.3703 - accuracy: 0.0000e+00 - precision_9: 0.1159\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 0s 884us/step - loss: 2.3320 - accuracy: 0.0000e+00 - precision_9: 0.1149\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 0s 874us/step - loss: 2.2912 - accuracy: 0.0000e+00 - precision_9: 0.1119\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 0s 960us/step - loss: 2.2460 - accuracy: 0.0000e+00 - precision_9: 0.1140\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 0s 859us/step - loss: 2.1979 - accuracy: 0.0000e+00 - precision_9: 0.1099\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 0s 869us/step - loss: 2.1425 - accuracy: 0.0000e+00 - precision_9: 0.1171\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 0s 842us/step - loss: 2.0915 - accuracy: 0.0000e+00 - precision_9: 0.1110\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 0s 802us/step - loss: 2.0330 - accuracy: 0.0000e+00 - precision_9: 0.1156\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 0s 856us/step - loss: 1.9663 - accuracy: 0.0000e+00 - precision_9: 0.1131\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 0s 844us/step - loss: 1.9055 - accuracy: 0.0000e+00 - precision_9: 0.1147\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 0s 880us/step - loss: 1.8365 - accuracy: 0.0000e+00 - precision_9: 0.1140\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 0s 985us/step - loss: 1.7669 - accuracy: 0.0000e+00 - precision_9: 0.1136\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 0s 837us/step - loss: 1.6958 - accuracy: 0.0000e+00 - precision_9: 0.1179\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 0s 897us/step - loss: 1.6200 - accuracy: 0.0000e+00 - precision_9: 0.1172\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 0s 849us/step - loss: 1.5556 - accuracy: 0.0000e+00 - precision_9: 0.1200\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 0s 947us/step - loss: 1.4872 - accuracy: 0.0000e+00 - precision_9: 0.1139\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.4246 - accuracy: 0.0000e+00 - precision_9: 0.1216\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.3601 - accuracy: 0.0000e+00 - precision_9: 0.1193\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.2958 - accuracy: 0.0000e+00 - precision_9: 0.1205\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.2373 - accuracy: 0.0000e+00 - precision_9: 0.1181\n",
      "Epoch 27/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.1818 - accuracy: 0.0000e+00 - precision_9: 0.1249\n",
      "Epoch 28/100\n",
      "7/7 [==============================] - 0s 811us/step - loss: 1.1188 - accuracy: 0.0000e+00 - precision_9: 0.1248\n",
      "Epoch 29/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.0653 - accuracy: 0.0000e+00 - precision_9: 0.1231\n",
      "Epoch 30/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.0112 - accuracy: 0.0000e+00 - precision_9: 0.1268\n",
      "Epoch 31/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.9735 - accuracy: 0.0000e+00 - precision_9: 0.1270\n",
      "Epoch 32/100\n",
      "7/7 [==============================] - 0s 938us/step - loss: 0.9234 - accuracy: 0.0000e+00 - precision_9: 0.1272\n",
      "Epoch 33/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.8741 - accuracy: 0.0000e+00 - precision_9: 0.1277\n",
      "Epoch 34/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.8317 - accuracy: 0.0000e+00 - precision_9: 0.1298\n",
      "Epoch 35/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.7960 - accuracy: 0.0000e+00 - precision_9: 0.1311\n",
      "Epoch 36/100\n",
      "7/7 [==============================] - 0s 917us/step - loss: 0.7560 - accuracy: 0.0000e+00 - precision_9: 0.1331\n",
      "Epoch 37/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.7203 - accuracy: 0.0000e+00 - precision_9: 0.1321\n",
      "Epoch 38/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6849 - accuracy: 0.0000e+00 - precision_9: 0.1330\n",
      "Epoch 39/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6528 - accuracy: 0.0000e+00 - precision_9: 0.1341\n",
      "Epoch 40/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6222 - accuracy: 0.0000e+00 - precision_9: 0.1343\n",
      "Epoch 41/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.5933 - accuracy: 0.0000e+00 - precision_9: 0.1404\n",
      "Epoch 42/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.5679 - accuracy: 0.0000e+00 - precision_9: 0.1376\n",
      "Epoch 43/100\n",
      "7/7 [==============================] - 0s 822us/step - loss: 0.5406 - accuracy: 0.0000e+00 - precision_9: 0.1410\n",
      "Epoch 44/100\n",
      "7/7 [==============================] - 0s 910us/step - loss: 0.5147 - accuracy: 0.0000e+00 - precision_9: 0.1411\n",
      "Epoch 45/100\n",
      "7/7 [==============================] - 0s 837us/step - loss: 0.4904 - accuracy: 0.0000e+00 - precision_9: 0.1441\n",
      "Epoch 46/100\n",
      "7/7 [==============================] - 0s 922us/step - loss: 0.4695 - accuracy: 0.0000e+00 - precision_9: 0.1448\n",
      "Epoch 47/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.4467 - accuracy: 0.0000e+00 - precision_9: 0.1480\n",
      "Epoch 48/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.4250 - accuracy: 0.0000e+00 - precision_9: 0.1480\n",
      "Epoch 49/100\n",
      "7/7 [==============================] - 0s 840us/step - loss: 0.4067 - accuracy: 0.0000e+00 - precision_9: 0.1483\n",
      "Epoch 50/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.3885 - accuracy: 0.0000e+00 - precision_9: 0.1509\n",
      "Epoch 51/100\n",
      "7/7 [==============================] - 0s 933us/step - loss: 0.3718 - accuracy: 0.0000e+00 - precision_9: 0.1505\n",
      "Epoch 52/100\n",
      "7/7 [==============================] - 0s 952us/step - loss: 0.3587 - accuracy: 0.0000e+00 - precision_9: 0.1549\n",
      "Epoch 53/100\n",
      "7/7 [==============================] - 0s 794us/step - loss: 0.3410 - accuracy: 0.0000e+00 - precision_9: 0.1557\n",
      "Epoch 54/100\n",
      "7/7 [==============================] - 0s 855us/step - loss: 0.3251 - accuracy: 0.0000e+00 - precision_9: 0.1565\n",
      "Epoch 55/100\n",
      "7/7 [==============================] - 0s 903us/step - loss: 0.3121 - accuracy: 0.0000e+00 - precision_9: 0.1586\n",
      "Epoch 56/100\n",
      "7/7 [==============================] - 0s 821us/step - loss: 0.2982 - accuracy: 0.0000e+00 - precision_9: 0.1555\n",
      "Epoch 57/100\n",
      "7/7 [==============================] - 0s 875us/step - loss: 0.2864 - accuracy: 0.0000e+00 - precision_9: 0.1582\n",
      "Epoch 58/100\n",
      "7/7 [==============================] - 0s 849us/step - loss: 0.2745 - accuracy: 0.0000e+00 - precision_9: 0.1589\n",
      "Epoch 59/100\n",
      "7/7 [==============================] - 0s 911us/step - loss: 0.2628 - accuracy: 0.0000e+00 - precision_9: 0.1632\n",
      "Epoch 60/100\n",
      "7/7 [==============================] - 0s 841us/step - loss: 0.2536 - accuracy: 0.0000e+00 - precision_9: 0.1646\n",
      "Epoch 61/100\n",
      "7/7 [==============================] - 0s 935us/step - loss: 0.2421 - accuracy: 0.0000e+00 - precision_9: 0.1630\n",
      "Epoch 62/100\n",
      "7/7 [==============================] - 0s 791us/step - loss: 0.2342 - accuracy: 0.0000e+00 - precision_9: 0.1654\n",
      "Epoch 63/100\n",
      "7/7 [==============================] - 0s 880us/step - loss: 0.2254 - accuracy: 0.0000e+00 - precision_9: 0.1663\n",
      "Epoch 64/100\n",
      "7/7 [==============================] - 0s 865us/step - loss: 0.2156 - accuracy: 0.0000e+00 - precision_9: 0.1691\n",
      "Epoch 65/100\n",
      "7/7 [==============================] - 0s 788us/step - loss: 0.2076 - accuracy: 0.0000e+00 - precision_9: 0.1719\n",
      "Epoch 66/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2003 - accuracy: 0.0000e+00 - precision_9: 0.1732\n",
      "Epoch 67/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.1933 - accuracy: 0.0000e+00 - precision_9: 0.1701\n",
      "Epoch 68/100\n",
      "7/7 [==============================] - 0s 949us/step - loss: 0.1862 - accuracy: 0.0000e+00 - precision_9: 0.1735\n",
      "Epoch 69/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.1792 - accuracy: 0.0000e+00 - precision_9: 0.1729\n",
      "Epoch 70/100\n",
      "7/7 [==============================] - 0s 915us/step - loss: 0.1727 - accuracy: 0.0000e+00 - precision_9: 0.1753\n",
      "Epoch 71/100\n",
      "7/7 [==============================] - 0s 920us/step - loss: 0.1673 - accuracy: 0.0000e+00 - precision_9: 0.1744\n",
      "Epoch 72/100\n",
      "7/7 [==============================] - 0s 843us/step - loss: 0.1620 - accuracy: 0.0000e+00 - precision_9: 0.1775\n",
      "Epoch 73/100\n",
      "7/7 [==============================] - 0s 847us/step - loss: 0.1559 - accuracy: 0.0000e+00 - precision_9: 0.1793\n",
      "Epoch 74/100\n",
      "7/7 [==============================] - 0s 892us/step - loss: 0.1506 - accuracy: 0.0000e+00 - precision_9: 0.1801\n",
      "Epoch 75/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.1463 - accuracy: 0.0000e+00 - precision_9: 0.1827\n",
      "Epoch 76/100\n",
      "7/7 [==============================] - 0s 866us/step - loss: 0.1417 - accuracy: 0.0000e+00 - precision_9: 0.1838\n",
      "Epoch 77/100\n",
      "7/7 [==============================] - 0s 952us/step - loss: 0.1370 - accuracy: 0.0000e+00 - precision_9: 0.1833\n",
      "Epoch 78/100\n",
      "7/7 [==============================] - 0s 855us/step - loss: 0.1321 - accuracy: 0.0000e+00 - precision_9: 0.1831\n",
      "Epoch 79/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.1284 - accuracy: 0.0000e+00 - precision_9: 0.1836\n",
      "Epoch 80/100\n",
      "7/7 [==============================] - 0s 895us/step - loss: 0.1243 - accuracy: 0.0000e+00 - precision_9: 0.1859\n",
      "Epoch 81/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.1221 - accuracy: 0.0000e+00 - precision_9: 0.1827\n",
      "Epoch 82/100\n",
      "7/7 [==============================] - 0s 946us/step - loss: 0.1179 - accuracy: 0.0000e+00 - precision_9: 0.1838\n",
      "Epoch 83/100\n",
      "7/7 [==============================] - 0s 885us/step - loss: 0.1140 - accuracy: 0.0000e+00 - precision_9: 0.1860\n",
      "Epoch 84/100\n",
      "7/7 [==============================] - 0s 843us/step - loss: 0.1108 - accuracy: 0.0000e+00 - precision_9: 0.1860\n",
      "Epoch 85/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.1076 - accuracy: 0.0000e+00 - precision_9: 0.1860\n",
      "Epoch 86/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.1051 - accuracy: 0.0000e+00 - precision_9: 0.1882\n",
      "Epoch 87/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.1019 - accuracy: 0.0000e+00 - precision_9: 0.1872\n",
      "Epoch 88/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0989 - accuracy: 0.0000e+00 - precision_9: 0.1883\n",
      "Epoch 89/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0964 - accuracy: 0.0000e+00 - precision_9: 0.1892\n",
      "Epoch 90/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0937 - accuracy: 0.0000e+00 - precision_9: 0.1892\n",
      "Epoch 91/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0918 - accuracy: 0.0000e+00 - precision_9: 0.1905\n",
      "Epoch 92/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.0891 - accuracy: 0.0000e+00 - precision_9: 0.1888\n",
      "Epoch 93/100\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.0869 - accuracy: 0.0000e+00 - precision_9: 0.1914\n",
      "Epoch 94/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0845 - accuracy: 0.0000e+00 - precision_9: 0.1931\n",
      "Epoch 95/100\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0824 - accuracy: 0.0000e+00 - precision_9: 0.1900\n",
      "Epoch 96/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0801 - accuracy: 0.0000e+00 - precision_9: 0.1935\n",
      "Epoch 97/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0785 - accuracy: 0.0000e+00 - precision_9: 0.1924\n",
      "Epoch 98/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0764 - accuracy: 0.0000e+00 - precision_9: 0.1914\n",
      "Epoch 99/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0745 - accuracy: 0.0000e+00 - precision_9: 0.1921\n",
      "Epoch 100/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0730 - accuracy: 0.0000e+00 - precision_9: 0.1909\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fdff8604eb0>"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train.toarray(), y_train, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 2ms/step\n",
      "0.6527777777777778\n",
      "0.689263963161022\n",
      "0.6599375061331583\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/max/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "predictions = model.predict(X_test.toarray())\n",
    "\n",
    "y_pred = np.array([np.argmax(pred) for pred in predictions])\n",
    "y_test_a = np.array([np.argmax(pred) for pred in y_test])\n",
    "\n",
    "\n",
    "\n",
    "# assert y_test_a.shape == y_pred.shape\n",
    "print(accuracy_score(y_test_a, y_pred))\n",
    "print(precision_score(y_test_a, y_pred, average=\"weighted\"))\n",
    "print(f1_score(y_test_a, y_pred, average=\"weighted\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 24ms/step\n",
      "state\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('address', 0.3506005),\n",
       " ('city', 0.6660605),\n",
       " ('country', 0.2535316),\n",
       " ('email', 0.45115393),\n",
       " ('housenumber', 0.6001632),\n",
       " ('lat', 0.2998368),\n",
       " ('location', 0.5115683),\n",
       " ('lon', 0.26927492),\n",
       " ('opening_hours', 0.6887708),\n",
       " ('phone', 0.25778553),\n",
       " ('placename', 0.33739865),\n",
       " ('postcode', 0.34698915),\n",
       " ('ref', 0.09894715),\n",
       " ('state', 0.9898834),\n",
       " ('store_url', 0.41442743),\n",
       " ('street', 0.23485182),\n",
       " ('unknown', 0.84018636)]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vect = vectorizer.transform([\"region\"]).toarray()\n",
    "\n",
    "prediction = model.predict(word_vect)\n",
    "\n",
    "print(l_encoder.classes_[np.argmax(prediction[0])])\n",
    "list(zip(l_encoder.classes_, prediction[0]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
